{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert + FARM for thesis Work.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0nbpX_X_lu2"
      },
      "source": [
        "Thesis Work.Using  Bert and FARM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTWktKyg_wzk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d5ffa92-8c19-43f8-c3af-edc4a77a56e7"
      },
      "source": [
        "!git clone https://github.com/deepset-ai/FARM.git\n",
        "!pip install -r FARM/requirements.txt\n",
        "!pip install FARM/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'FARM'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 6438 (delta 49), reused 43 (delta 26), pack-reused 6352\u001b[K\n",
            "Receiving objects: 100% (6438/6438), 65.76 MiB | 23.57 MiB/s, done.\n",
            "Resolving deltas: 100% (4808/4808), done.\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from -r FARM/requirements.txt (line 2)) (49.6.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from -r FARM/requirements.txt (line 3)) (0.35.1)\n",
            "Collecting torch<=1.6.0,>=1.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/53/914885a93a44b96c0dd1c36f36ff10afe341f091230aad68f7228d61db1e/torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8MB 25kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r FARM/requirements.txt (line 8)) (4.41.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from -r FARM/requirements.txt (line 10)) (1.14.48)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from -r FARM/requirements.txt (line 12)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.6/dist-packages (from -r FARM/requirements.txt (line 14)) (1.4.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r FARM/requirements.txt (line 15)) (0.0)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Collecting mlflow==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/ec/8c9448968d4662e8354b9c3a62e635f8929ed507a45af3d9fdb84be51270/mlflow-1.0.0-py3-none-any.whl (47.7MB)\n",
            "\u001b[K     |████████████████████████████████| 47.7MB 62kB/s \n",
            "\u001b[?25hCollecting transformers==3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 39.3MB/s \n",
            "\u001b[?25hCollecting dotmap==1.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/fa/eb/ee5f0358a9e0ede90308d8f34e697e122f191c2702dc4f614eca7770b1eb/dotmap-1.3.0-py3-none-any.whl\n",
            "Collecting Werkzeug==0.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/e4/a859d2fe516f466642fa5c6054fd9646271f9da26b0cac0d2f37fc858c8f/Werkzeug-0.16.1-py2.py3-none-any.whl (327kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from -r FARM/requirements.txt (line 25)) (1.1.2)\n",
            "Collecting flask-restplus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/a6/b17c848771f96ad039ad9e3ea275e842a16c39c4f3eb9f60ee330b20b6c2/flask_restplus-0.13.0-py2.py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 22.0MB/s \n",
            "\u001b[?25hCollecting flask-cors\n",
            "  Downloading https://files.pythonhosted.org/packages/69/7f/d0aeaaafb5c3c76c8d2141dbe2d4f6dca5d6c31872d4e5349768c1958abc/Flask_Cors-3.0.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from -r FARM/requirements.txt (line 28)) (0.3.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from -r FARM/requirements.txt (line 32)) (5.4.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch<=1.6.0,>=1.5.1->-r FARM/requirements.txt (line 6)) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<=1.6.0,>=1.5.1->-r FARM/requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->-r FARM/requirements.txt (line 10)) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.48 in /usr/local/lib/python3.6/dist-packages (from boto3->-r FARM/requirements.txt (line 10)) (1.17.48)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->-r FARM/requirements.txt (line 10)) (0.3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->-r FARM/requirements.txt (line 12)) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->-r FARM/requirements.txt (line 12)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->-r FARM/requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->-r FARM/requirements.txt (line 12)) (2.10)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r FARM/requirements.txt (line 15)) (0.22.2.post1)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->-r FARM/requirements.txt (line 17)) (2.4.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->-r FARM/requirements.txt (line 18)) (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->-r FARM/requirements.txt (line 18)) (3.12.4)\n",
            "Collecting querystring-parser\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/fa/f54f5662e0eababf0c49e92fd94bf178888562c0e7b677c8941bbbcd1bd6/querystring_parser-1.2.4.tar.gz\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->-r FARM/requirements.txt (line 18)) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->-r FARM/requirements.txt (line 18)) (2.8.1)\n",
            "Collecting gitpython>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/bc/ae32e07e89cc25b9e5c793d19a1e5454d30a8e37d95040991160f942519e/GitPython-3.1.8-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->-r FARM/requirements.txt (line 18)) (3.13)\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1e/cabc75a189de0fbb2841d0975243e59bde8b7822bacbb95008ac6fe9ad47/alembic-1.4.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 36.4MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gunicorn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.4MB/s \n",
            "\u001b[?25hCollecting databricks-cli>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/57/5c2d6b83cb8753d12f548e89f91037632baa8289677c1b2ab2adf14bf6b2/databricks-cli-0.11.0.tar.gz (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->-r FARM/requirements.txt (line 18)) (0.3)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->-r FARM/requirements.txt (line 18)) (0.3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->-r FARM/requirements.txt (line 18)) (1.0.5)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->-r FARM/requirements.txt (line 18)) (1.3.19)\n",
            "Collecting simplejson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/96/1e6b19045375890068d7342cbe280dd64ae73fd90b9735b5efb8d1e044a1/simplejson-3.17.2-cp36-cp36m-manylinux2010_x86_64.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 38.5MB/s \n",
            "\u001b[?25hCollecting docker>=3.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/8c/8d42dbd83679483db207535f4fb02dc84325fa78b290f057694b057fcd21/docker-4.3.1-py2.py3-none-any.whl (145kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->-r FARM/requirements.txt (line 18)) (7.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0->-r FARM/requirements.txt (line 20)) (3.0.12)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 31.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0->-r FARM/requirements.txt (line 20)) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 34.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0->-r FARM/requirements.txt (line 20)) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 36.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0->-r FARM/requirements.txt (line 20)) (20.4)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->-r FARM/requirements.txt (line 25)) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->-r FARM/requirements.txt (line 25)) (2.11.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from flask-restplus->-r FARM/requirements.txt (line 26)) (2.6.0)\n",
            "Collecting aniso8601>=0.82\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/e4/787e104b58eadc1a710738d4e418d7e599e4e778e52cb8e5d5ef6ddd5833/aniso8601-8.0.0-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from flask-restplus->-r FARM/requirements.txt (line 26)) (2018.9)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->-r FARM/requirements.txt (line 10)) (0.15.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r FARM/requirements.txt (line 15)) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r FARM/requirements.txt (line 17)) (2.10.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.1MB/s \n",
            "\u001b[?25hCollecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.8MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.0->mlflow==1.0.0->-r FARM/requirements.txt (line 18)) (0.8.7)\n",
            "Collecting websocket-client>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 42.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.1.0->-r FARM/requirements.txt (line 20)) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->-r FARM/requirements.txt (line 25)) (1.1.1)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: alembic\n",
            "  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.2-cp36-none-any.whl size=159540 sha256=0ba980207a737fa14e42bfaf92e77d4d2898641c728dce0f441dd3876be847ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/04/83/76023f7a4c14688c0b5c2682a96392cfdd3ee4449eaaa287ef\n",
            "Successfully built alembic\n",
            "Building wheels for collected packages: seqeval, querystring-parser, databricks-cli, sacremoses\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7423 sha256=b2cf4bef3d030547404a18cf5ff4037f2036c00b74beb3a3bc36cd0d4cb44215\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "  Building wheel for querystring-parser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for querystring-parser: filename=querystring_parser-1.2.4-cp36-none-any.whl size=7078 sha256=fc706d46cba0ae6df06c19d6addda45e10bdf1dd7db2506cb72ae6655cc8a232\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/41/34/23ebf5d1089a9aed847951e0ee375426eb4ad0a7079d88d41e\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.11.0-cp36-none-any.whl size=90301 sha256=707de5c59da7b565c74a51b942a2d02d8355206cc737850930dcbf8cb679a7ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/d0/4f/3deeca1f4c47a6aca7c2c6a6e2bf272391565dc86a7718a59b\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=941e1beecef5c1d4a1a0b4e12a1b4bb78f6274eae0545da790b54f1ae3e979ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built seqeval querystring-parser databricks-cli sacremoses\n",
            "Installing collected packages: torch, seqeval, querystring-parser, smmap, gitdb, gitpython, Mako, python-editor, alembic, gunicorn, databricks-cli, simplejson, websocket-client, docker, mlflow, tokenizers, sentencepiece, sacremoses, transformers, dotmap, Werkzeug, aniso8601, flask-restplus, flask-cors\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "Successfully installed Mako-1.1.3 Werkzeug-0.16.1 alembic-1.4.2 aniso8601-8.0.0 databricks-cli-0.11.0 docker-4.3.1 dotmap-1.3.0 flask-cors-3.0.9 flask-restplus-0.13.0 gitdb-4.0.5 gitpython-3.1.8 gunicorn-20.0.4 mlflow-1.0.0 python-editor-1.0.4 querystring-parser-1.2.4 sacremoses-0.0.43 sentencepiece-0.1.91 seqeval-0.0.12 simplejson-3.17.2 smmap-3.0.4 tokenizers-0.8.1rc2 torch-1.6.0 transformers-3.1.0 websocket-client-0.57.0\n",
            "Processing ./FARM\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (49.6.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (0.35.1)\n",
            "Requirement already satisfied: torch<=1.6.0,>=1.5.1 in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (1.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (4.41.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (1.14.48)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (1.4.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (0.0)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (0.0.12)\n",
            "Requirement already satisfied: mlflow==1.0.0 in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (1.0.0)\n",
            "Requirement already satisfied: transformers==3.1.0 in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (3.1.0)\n",
            "Requirement already satisfied: dotmap==1.3.0 in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (1.3.0)\n",
            "Requirement already satisfied: Werkzeug==0.16.1 in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (0.16.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (1.1.2)\n",
            "Requirement already satisfied: flask-restplus in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (0.13.0)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (3.0.9)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (0.3.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from farm==0.4.7) (5.4.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch<=1.6.0,>=1.5.1->farm==0.4.7) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<=1.6.0,>=1.5.1->farm==0.4.7) (0.16.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->farm==0.4.7) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->farm==0.4.7) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.48 in /usr/local/lib/python3.6/dist-packages (from boto3->farm==0.4.7) (1.17.48)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->farm==0.4.7) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->farm==0.4.7) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->farm==0.4.7) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->farm==0.4.7) (2020.6.20)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->farm==0.4.7) (0.22.2.post1)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->farm==0.4.7) (2.4.3)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (3.17.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (1.0.5)\n",
            "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (3.1.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (2.8.1)\n",
            "Requirement already satisfied: databricks-cli>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (0.11.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (1.15.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (1.4.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (3.13)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (7.1.2)\n",
            "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (1.2.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (0.3)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (0.3.1)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (1.3.19)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (3.12.4)\n",
            "Requirement already satisfied: docker>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (4.3.1)\n",
            "Requirement already satisfied: gunicorn in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (20.0.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow==1.0.0->farm==0.4.7) (1.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0->farm==0.4.7) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0->farm==0.4.7) (0.8.1rc2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0->farm==0.4.7) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0->farm==0.4.7) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0->farm==0.4.7) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0->farm==0.4.7) (0.7)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0->farm==0.4.7) (0.1.91)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->farm==0.4.7) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->farm==0.4.7) (2.11.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from flask-restplus->farm==0.4.7) (2.6.0)\n",
            "Requirement already satisfied: aniso8601>=0.82 in /usr/local/lib/python3.6/dist-packages (from flask-restplus->farm==0.4.7) (8.0.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from flask-restplus->farm==0.4.7) (2018.9)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->farm==0.4.7) (0.15.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->farm==0.4.7) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->farm==0.4.7) (2.10.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from gitpython>=2.1.0->mlflow==1.0.0->farm==0.4.7) (4.0.5)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.0->mlflow==1.0.0->farm==0.4.7) (0.8.7)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic->mlflow==1.0.0->farm==0.4.7) (1.0.4)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.6/dist-packages (from alembic->mlflow==1.0.0->farm==0.4.7) (1.1.3)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from docker>=3.6.0->mlflow==1.0.0->farm==0.4.7) (0.57.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.1.0->farm==0.4.7) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->farm==0.4.7) (1.1.1)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow==1.0.0->farm==0.4.7) (3.0.4)\n",
            "Building wheels for collected packages: farm\n",
            "  Building wheel for farm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for farm: filename=farm-0.4.7-cp36-none-any.whl size=189242 sha256=0a808576ce0b0f23d2f9e8bf7aa4fd854571e24e99707bf10371e35be528221c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-48vmmdof/wheels/6c/de/cd/14938f303de422b13115b36fb077c42e58bf8e2734756d64da\n",
            "Successfully built farm\n",
            "Installing collected packages: farm\n",
            "Successfully installed farm-0.4.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm9CJTcDOR7G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "04fb2226-8162-49ff-861a-b96befbfcecf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/3wEKLoEcimSzgcM7IrTanzqbNW9hBbvgjivGS0FoTTJM4HUcyyhj_-w\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sc2uoBY4vrQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1d2b4ae2-0b5d-470d-dae0-ec7a96be033e"
      },
      "source": [
        "!git clone https://github.com/guggio/bbc_news"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bbc_news'...\n",
            "remote: Enumerating objects: 2203, done.\u001b[K\n",
            "remote: Counting objects: 100% (2203/2203), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2177/2177), done.\u001b[K\n",
            "remote: Total 2203 (delta 28), reused 2189 (delta 18), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2203/2203), 5.18 MiB | 4.20 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkiNyYl5A8AW"
      },
      "source": [
        "from farm.data_handler.data_silo import DataSilo\n",
        "from farm.data_handler.processor import TextClassificationProcessor\n",
        "from farm.modeling.optimization import initialize_optimizer\n",
        "from farm.infer import Inferencer\n",
        "from farm.modeling.adaptive_model import AdaptiveModel\n",
        "from farm.modeling.language_model import LanguageModel\n",
        "from farm.modeling.prediction_head import MultiLabelTextClassificationHead\n",
        "from farm.modeling.tokenization import Tokenizer\n",
        "from farm.train import Trainer\n",
        "from farm.utils import set_all_seeds, MLFlowLogger, initialize_device_settings\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjQOzMToLJUl"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/Hate/NewFileTD.txt',sep='\\t', encoding='utf-8',names=[\"text\", \"label\"])\n",
        "\n",
        "#df.to_csv('/content/drive/My Drive/FinalProperTwoCdata',sep='\\t')\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\n",
        "# determine the path where to save the train and test file\n",
        "train_path = Path('/content/drive/My Drive/Hate/Train/', 'train.tsv')\n",
        "test_path = Path('/content/drive/My Drive/Hate/Test/', 'test.tsv')\n",
        "\n",
        "# save the train and test file\n",
        "# again using the '\\t' separator to create tab-separated-values files\n",
        "train.to_csv(train_path )\n",
        "test.to_csv(test_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fELe_6IkLJUn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "19d8a9b2-fce0-4b85-def6-05f989e97a5a"
      },
      "source": [
        "ml_logger = MLFlowLogger(tracking_uri=\"https://public-mlflow.deepset.ai/\")\n",
        "ml_logger.init_experiment(experiment_name=\"ADRs\", run_name=\"Thesis Work\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " __          __  _                            _        \n",
            " \\ \\        / / | |                          | |       \n",
            "  \\ \\  /\\  / /__| | ___ ___  _ __ ___   ___  | |_ ___  \n",
            "   \\ \\/  \\/ / _ \\ |/ __/ _ \\| '_ ` _ \\ / _ \\ | __/ _ \\ \n",
            "    \\  /\\  /  __/ | (_| (_) | | | | | |  __/ | || (_) |\n",
            "     \\/  \\/ \\___|_|\\___\\___/|_| |_| |_|\\___|  \\__\\___/ \n",
            "  ______      _____  __  __  \n",
            " |  ____/\\   |  __ \\|  \\/  |              _.-^-._    .--.\n",
            " | |__ /  \\  | |__) | \\  / |           .-'   _   '-. |__|\n",
            " |  __/ /\\ \\ |  _  /| |\\/| |          /     |_|     \\|  |\n",
            " | | / ____ \\| | \\ \\| |  | |         /               \\  |\n",
            " |_|/_/    \\_\\_|  \\_\\_|  |_|        /|     _____     |\\ |\n",
            "                                     |    |==|==|    |  |\n",
            "|---||---|---|---|---|---|---|---|---|    |--|--|    |  |\n",
            "|---||---|---|---|---|---|---|---|---|    |==|==|    |  |\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRloyzjFLJUq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6f4d6ab5-f7c1-44a9-bd43-e6c223ffd34a"
      },
      "source": [
        "set_all_seeds(seed=42)\n",
        "device, n_gpu = initialize_device_settings(use_cuda=True)\n",
        "n_epochs = 5\n",
        "batch_size = 16 # larger batch sizes might use too much computing power in Colab\n",
        "evaluate_every = 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "09/10/2020 15:33:41 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFrc64keLJUs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "6cf769e7-49e3-4709-d79d-b97bd2449794"
      },
      "source": [
        "lang_model = \"bert-base-cased\"\n",
        "do_lower_case = False\n",
        "\n",
        "tokenizer = Tokenizer.load(\n",
        "    pretrained_model_name_or_path=lang_model,\n",
        "    do_lower_case=do_lower_case)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-35b3ed23f842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdo_lower_case\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m tokenizer = Tokenizer.load(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlang_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     do_lower_case=do_lower_case)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InejlHJdLJUv"
      },
      "source": [
        "label_list = ['Text','Label'] #labels in our data set\n",
        "metric = \"f1_macro\" # desired metric for evaluation\n",
        "\n",
        "processor = TextClassificationProcessor(tokenizer=tokenizer,\n",
        "                                            max_seq_len=512, # BERT can only handle sequence lengths of up to 512\n",
        "                                            data_dir='/content/drive/My Drive/Hate/FinalDS', \n",
        "                                            label_list=label_list,\n",
        "                                            label_column_name=\"label\", # our labels are located in the \"genre\" column\n",
        "                                            metric=metric,\n",
        "                                            quote_char='\"',\n",
        "                                            multilabel=True,\n",
        "                                            train_filename=\"train.tsv\",\n",
        "                                            dev_filename=None,\n",
        "                                            test_filename=\"test.tsv\",\n",
        "                                            dev_split=0.1 # this will extract 10% of the train set to create a dev set\n",
        "                                            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34-8Q0wfCjLA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "5972a1f4-1b6b-4b5a-ed26-ae38084cd5d5"
      },
      "source": [
        "data_silo = DataSilo(\n",
        "    processor=processor,\n",
        "    batch_size=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "09/10/2020 15:34:26 - INFO - farm.data_handler.data_silo -   \n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|       \n",
            " (o)(o)------'\\ _ /     ( )      \n",
            " \n",
            "09/10/2020 15:34:26 - INFO - farm.data_handler.data_silo -   Loading train set from: /content/drive/My Drive/Hate/FinalDS/train.tsv \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-1ec7619fe8fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m data_silo = DataSilo(\n\u001b[1;32m      2\u001b[0m     \u001b[0mprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     batch_size=8)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/farm/data_handler/data_silo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, processor, batch_size, distributed, automatic_loading, max_multiprocessing_chunksize, max_processes, caching, cache_path)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# In most cases we want to load all data automatically, but in some cases we rather want to do this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# later or load from dicts instead of file (https://github.com/deepset-ai/FARM/issues/85)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/farm/data_handler/data_silo.py\u001b[0m in \u001b[0;36m_load_data\u001b[0;34m(self, train_dicts, dev_dicts, test_dicts)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mtrain_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading train set from: {} \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No train set is being loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/farm/data_handler/data_silo.py\u001b[0m in \u001b[0;36m_get_dataset\u001b[0;34m(self, filename, dicts)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m# loading dicts from file (default)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdicts\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mdicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_to_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;31m#shuffle list of dicts here if we later want to have a random dev set splitted from train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_filename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/farm/data_handler/processor.py\u001b[0m in \u001b[0;36mfile_to_dicts\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             )\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/farm/data_handler/utils.py\u001b[0m in \u001b[0;36mread_tsv\u001b[0;34m(filename, rename_columns, quotechar, delimiter, skiprows, header, proxies, max_samples)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     )\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1935\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1936\u001b[0m             ):\n\u001b[0;32m-> 1937\u001b[0;31m                 \u001b[0m_validate_usecols_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_validate_usecols_names\u001b[0;34m(usecols, names)\u001b[0m\n\u001b[1;32m   1231\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         raise ValueError(\n\u001b[0;32m-> 1233\u001b[0;31m             \u001b[0;34m\"Usecols do not match columns, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m             \u001b[0;34mf\"columns expected but not found: {missing}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['text', 'label']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuwU5DmyCnKd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "a71785d9-799d-4d04-ff02-e2620e81eefd"
      },
      "source": [
        "# loading the pretrained BERT base cased model\n",
        "language_model = LanguageModel.load(lang_model)\n",
        "# prediction head for our model that is suited for classifying news article genres\n",
        "prediction_head = MultiLabelTextClassificationHead(num_labels=len(label_list))\n",
        "\n",
        "model = AdaptiveModel(\n",
        "        language_model=language_model,\n",
        "        prediction_heads=[prediction_head],\n",
        "        embeds_dropout_prob=0.1,\n",
        "        lm_output_types=[\"per_sequence\"],\n",
        "        device=device)\n",
        "\n",
        "model, optimizer, lr_schedule = initialize_optimizer(\n",
        "        model=model,\n",
        "        learning_rate=3e-5,\n",
        "        device=device,\n",
        "        n_batches=8,\n",
        "        n_epochs=n_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "09/10/2020 15:13:19 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
            "\t We guess it's an *ENGLISH* model ... \n",
            "\t If not: Init the language model by supplying the 'language' param.\n",
            "09/10/2020 15:13:19 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
            "09/10/2020 15:13:22 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 3e-05}'\n",
            "09/10/2020 15:13:24 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
            "09/10/2020 15:13:24 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 4.0, 'num_training_steps': 40}'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMjDt6-sC3ZS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "d5afc5e6-cf3c-40dd-f3a6-2607462f03b2"
      },
      "source": [
        "trainer = Trainer(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        data_silo=data_silo,\n",
        "        epochs=n_epochs,\n",
        "        n_gpu=n_gpu,\n",
        "        lr_schedule=lr_schedule,\n",
        "        evaluate_every=evaluate_every, # we defined this value in the setup section. We set it to 100\n",
        "        device=device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-49d9f8081a87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mdata_silo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_silo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mn_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_silo' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGzPs-_yC91b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d273190-aec4-4289-f367-7e1574fc9299"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/29/2020 17:36:36 - INFO - farm.train -   \n",
            " \n",
            "\n",
            "          &&& &&  & &&             _____                   _             \n",
            "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
            "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
            "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
            "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
            "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
            " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
            "     &&     \\|||                                                   |___/\n",
            "             |||\n",
            "             |||\n",
            "             |||\n",
            "       , -=-~  .-^- _\n",
            "              `\n",
            "\n",
            "Train epoch 0/4 (Cur. train loss: 0.0183):  26%|██▌       | 100/390 [01:19<03:40,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  39%|███▉      | 38/97 [00:10<00:15,  3.73it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.66it/s]\n",
            "07/29/2020 17:38:23 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 100 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 17:38:23 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 17:38:23 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 17:38:23 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 17:38:24 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 17:38:24 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 0/4 (Cur. train loss: 0.0110):  51%|█████▏    | 200/390 [03:07<02:23,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.65it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.64it/s]\n",
            "07/29/2020 17:40:11 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 200 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 17:40:11 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 17:40:12 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 17:40:12 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 17:40:13 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 17:40:13 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 0/4 (Cur. train loss: 0.0111):  77%|███████▋  | 300/390 [04:56<01:08,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.64it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.64it/s]\n",
            "07/29/2020 17:42:00 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 300 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 17:42:00 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 17:42:01 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 17:42:01 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 17:42:01 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 17:42:01 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 0/4 (Cur. train loss: 0.6462): 100%|██████████| 390/390 [06:37<00:00,  1.02s/it]\n",
            "Train epoch 1/4 (Cur. train loss: 0.0111):   3%|▎         | 10/390 [00:08<04:53,  1.29it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.65it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.64it/s]\n",
            "07/29/2020 17:43:49 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 400 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 17:43:49 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 17:43:49 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 17:43:49 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 17:43:50 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 17:43:50 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 1/4 (Cur. train loss: 0.0159):  28%|██▊       | 110/390 [01:56<03:32,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.65it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n",
            "07/29/2020 17:45:37 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 500 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 17:45:37 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 17:45:38 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 17:45:38 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 17:45:39 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 17:45:39 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 1/4 (Cur. train loss: 0.0160):  54%|█████▍    | 210/390 [03:45<02:16,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.65it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n",
            "07/29/2020 17:47:26 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 600 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 17:47:26 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 17:47:27 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 17:47:27 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 17:47:27 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 17:47:27 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 1/4 (Cur. train loss: 0.0111):  79%|███████▉  | 310/390 [05:34<01:00,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.66it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.66it/s]\n",
            "07/29/2020 17:49:15 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 700 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 17:49:15 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 17:49:15 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 17:49:15 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 17:49:16 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 17:49:16 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 1/4 (Cur. train loss: 0.6412): 100%|██████████| 390/390 [07:06<00:00,  1.09s/it]\n",
            "Train epoch 2/4 (Cur. train loss: 0.0062):   5%|▌         | 20/390 [00:16<04:40,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.65it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n",
            "07/29/2020 17:51:03 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 800 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 17:51:03 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 17:51:04 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 17:51:04 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 17:51:05 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 17:51:05 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 2/4 (Cur. train loss: 1.0380):  31%|███       | 120/390 [02:04<03:24,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.65it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n",
            "07/29/2020 17:52:52 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 900 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 17:52:52 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 17:52:53 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 17:52:53 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 17:52:53 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 17:52:53 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 2/4 (Cur. train loss: 0.0111):  56%|█████▋    | 220/390 [03:53<02:08,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.64it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n",
            "07/29/2020 17:54:41 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 1000 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 17:54:41 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 17:54:42 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 17:54:42 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 17:54:42 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 17:54:42 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 2/4 (Cur. train loss: 0.0159):  82%|████████▏ | 320/390 [05:42<00:52,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.66it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.64it/s]\n",
            "07/29/2020 17:56:30 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 1100 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 17:56:30 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 17:56:30 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 17:56:30 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 17:56:31 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 17:56:31 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 2/4 (Cur. train loss: 0.0063): 100%|██████████| 390/390 [07:06<00:00,  1.09s/it]\n",
            "Train epoch 3/4 (Cur. train loss: 0.0111):   8%|▊         | 30/390 [00:24<04:32,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.66it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n",
            "07/29/2020 17:58:18 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 1200 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 17:58:18 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 17:58:19 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 17:58:19 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 17:58:20 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 17:58:20 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 3/4 (Cur. train loss: 0.0111):  33%|███▎      | 130/390 [02:12<03:16,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.66it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.66it/s]\n",
            "07/29/2020 18:00:07 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 1300 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 18:00:07 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 18:00:08 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 18:00:08 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 18:00:08 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 18:00:08 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 3/4 (Cur. train loss: 0.4109):  59%|█████▉    | 230/390 [04:01<02:01,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.65it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n",
            "07/29/2020 18:01:56 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 1400 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 18:01:56 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 18:01:56 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 18:01:56 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 18:01:57 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 18:01:57 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 3/4 (Cur. train loss: 0.0304):  85%|████████▍ | 330/390 [05:50<00:45,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.65it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n",
            "07/29/2020 18:03:44 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 1500 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 18:03:44 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 18:03:45 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 18:03:45 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 18:03:46 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 18:03:46 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 3/4 (Cur. train loss: 0.6348): 100%|██████████| 390/390 [07:06<00:00,  1.09s/it]\n",
            "Train epoch 4/4 (Cur. train loss: 0.0208):  10%|█         | 40/390 [00:32<04:24,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.65it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.66it/s]\n",
            "07/29/2020 18:05:33 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 1600 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 18:05:33 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 18:05:34 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 18:05:34 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 18:05:34 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 18:05:34 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 4/4 (Cur. train loss: 0.0159):  36%|███▌      | 140/390 [02:20<03:08,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.65it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n",
            "07/29/2020 18:07:22 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 1700 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 18:07:22 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 18:07:22 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 18:07:22 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 18:07:23 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 18:07:23 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 4/4 (Cur. train loss: 0.0062):  62%|██████▏   | 240/390 [04:09<01:53,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.65it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n",
            "07/29/2020 18:09:10 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 1800 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 18:09:10 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 18:09:11 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 18:09:11 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 18:09:12 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 18:09:12 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 4/4 (Cur. train loss: 0.0207):  87%|████████▋ | 340/390 [05:58<00:37,  1.32it/s]\n",
            "Evaluating:   0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 37/97 [00:10<00:16,  3.65it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n",
            "07/29/2020 18:10:59 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 1900 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 18:10:59 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 18:11:00 - INFO - farm.eval -   loss: 0.06330591442601122\n",
            "07/29/2020 18:11:00 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 18:11:00 - INFO - farm.eval -   f1_macro: 0.9834717784877529\n",
            "07/29/2020 18:11:00 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9889    0.9984    0.9936       623\n",
            "          NO     0.9932    0.9542    0.9733       153\n",
            "\n",
            "   micro avg     0.9897    0.9897    0.9897       776\n",
            "   macro avg     0.9910    0.9763    0.9835       776\n",
            "weighted avg     0.9897    0.9897    0.9896       776\n",
            " samples avg     0.9897    0.9897    0.9897       776\n",
            "\n",
            "Train epoch 4/4 (Cur. train loss: 0.0159): 100%|██████████| 390/390 [07:06<00:00,  1.09s/it]\n",
            "Evaluating: 100%|██████████| 122/122 [00:33<00:00,  3.65it/s]\n",
            "07/29/2020 18:12:13 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 1950 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "07/29/2020 18:12:13 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "07/29/2020 18:12:13 - INFO - farm.eval -   loss: 0.08052286845751298\n",
            "07/29/2020 18:12:13 - INFO - farm.eval -   task_name: text_classification\n",
            "07/29/2020 18:12:14 - INFO - farm.eval -   f1_macro: 0.9747201935957823\n",
            "07/29/2020 18:12:14 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         YES     0.9874    0.9937    0.9905       790\n",
            "          NO     0.9722    0.9459    0.9589       185\n",
            "\n",
            "   micro avg     0.9846    0.9846    0.9846       975\n",
            "   macro avg     0.9798    0.9698    0.9747       975\n",
            "weighted avg     0.9845    0.9846    0.9845       975\n",
            " samples avg     0.9846    0.9846    0.9846       975\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaptiveModel(\n",
              "  (language_model): Bert(\n",
              "    (model): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (prediction_heads): ModuleList(\n",
              "    (0): MultiLabelTextClassificationHead(\n",
              "      (feed_forward): FeedForwardBlock(\n",
              "        (feed_forward): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=2, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (loss_fct): BCEWithLogitsLoss()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2GUkw1ZDCv4"
      },
      "source": [
        "save_dir = \"saved_models/bert-english-news-article\"\n",
        "model.save(save_dir)\n",
        "processor.save(save_dir)\n",
        "\n",
        "inferenced_model = Inferencer.load(save_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Mr7ynnuDWFB"
      },
      "source": [
        "!zip -r saved_models/model.zip saved_models/bert-english-news-article"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fka_y4lcAP2P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "2f6620fa-7c0a-4d47-f8c9-a184fba84f8f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/FinalProperTwoCdata/mytsv4.tsv',sep='\\t')\n",
        "\n",
        "#df.to_csv('/content/drive/My Drive/FinalProperTwoCdata',sep='\\t')\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "# determine the path where to save the train and test file\n",
        "train_path = Path('/content/drive/My Drive/FinalProperTwoCdata/', 'train.tsv')\n",
        "test_path = Path('/content/drive/My Drive/FinalProperTwoCdata/', 'test.tsv')\n",
        "\n",
        "# save the train and test file\n",
        "# again using the '\\t' separator to create tab-separated-values files\n",
        "train.to_csv(train_path, sep='\\t', index=False)\n",
        "test.to_csv(test_path, sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-bcf79cd5a578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/FinalProperTwoCdata/mytsv4.tsv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#df.to_csv('/content/drive/My Drive/FinalProperTwoCdata',sep='\\t')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /content/drive/My Drive/FinalProperTwoCdata/mytsv4.tsv does not exist: '/content/drive/My Drive/FinalProperTwoCdata/mytsv4.tsv'"
          ]
        }
      ]
    }
  ]
}